{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model\n",
      "finised\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as functional\n",
    "import model\n",
    "from model import xavier_init\n",
    "from model import weights_init\n",
    "from myfolder import ImageFolder\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import csv\n",
    "data_path = './dataset/leaves'\n",
    "\n",
    "#convert array to unit8 (ot display the image)\n",
    "def arr2unit8(arr):\n",
    "    #arr m*n\n",
    "#     img_numpy = input.data[0,:,:,:].cpu().numpy()[0,:,:] variable\n",
    "    res = np.zeros((arr.shape[0],arr.shape[1]),dtype=np.uint8)\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            if arr[i][j] > 0.5:\n",
    "                res[i][j] = 255\n",
    "    return res\n",
    "        \n",
    "#save results\n",
    "class leaf_save:\n",
    "    def __init__(self, classes, filename='sample_submission.csv'):\n",
    "        first_row = ['id']\n",
    "        first_row.extend(classes)\n",
    "        self.csvfile = file(filename, 'wb')\n",
    "        self.csv_writer = csv.writer(self.csvfile)\n",
    "        self.csv_writer.writerow(first_row)\n",
    "    \n",
    "    def write_data(self, result):\n",
    "        self.csv_writer.writerows(result)\n",
    "        \n",
    "    def close(self):\n",
    "        self.csvfile.close()\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #train or test\n",
    "    phase = 'test'\n",
    "#     phase = 'test'\n",
    "    #batch size\n",
    "    nb = 128\n",
    "    is_cuda = True\n",
    "    random.seed(random.randint(1,10000))\n",
    "    torch.manual_seed(random.randint(1,10000))\n",
    "    pretrain_model = 'models/epoch_49.pth'\n",
    "    if phase == 'train':\n",
    "        pretrain_model = ''\n",
    "    #use cudnn\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    #Normalized to (0,1)\n",
    "    normalization = transforms.Normalize((0., 0., 0.),(1., 1., 1.))\n",
    "#     normalization = transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "    if phase == 'train':\n",
    "        trainset = ImageFolder(root=data_path+'/train', \\\n",
    "                transform=transforms.Compose([\\\n",
    "                transforms.ToTensor(),\n",
    "                normalization\n",
    "                ]))\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, batch_size = nb,\\\n",
    "                shuffle=True, num_workers = 2)\n",
    "\n",
    "\n",
    "        valset = ImageFolder(root=data_path+'/val', \\\n",
    "                transform=transforms.Compose([\\\n",
    "                transforms.ToTensor(),\n",
    "                normalization\n",
    "                ]))\n",
    "        #198 all val images\n",
    "        val_loader = torch.utils.data.DataLoader(valset, batch_size = 198,\\\n",
    "                shuffle=True, num_workers = 2)\n",
    "    if phase == 'test':\n",
    "        testset = ImageFolder(root=data_path+'/test', \\\n",
    "                transform=transforms.Compose([\\\n",
    "                transforms.ToTensor(),\n",
    "                normalization\n",
    "                ]))\n",
    "        test_loader = torch.utils.data.DataLoader(testset, batch_size = 1,\\\n",
    "                shuffle=False, num_workers = 1)\n",
    "\n",
    "    # network\n",
    "    net = model.leafnet(1)\n",
    "    net.apply(xavier_init)\n",
    "    if pretrain_model != '':\n",
    "        print 'loading pretrained model'\n",
    "        net.load_state_dict(torch.load(pretrain_model))\n",
    "    \n",
    "    \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    input = torch.FloatTensor(nb, 1, 96, 96)\n",
    "    label = torch.LongTensor(nb)\n",
    "    input_att = torch.FloatTensor(nb, 192)\n",
    "    if is_cuda: \n",
    "        net.cuda()\n",
    "        criterion.cuda()\n",
    "        input = input.cuda()\n",
    "        label = label.cuda()\n",
    "        input_att = input_att.cuda()\n",
    "\n",
    "    input = Variable(input)\n",
    "    label = Variable(label)\n",
    "    input_att = Variable(input_att)\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=0.02, momentum=0.9)\n",
    "#     optimizer = optim.RMSprop(net.parameters(), lr = 0.01, momentum=0.9)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01, betas = (.5, 0.999))\n",
    "    \n",
    "    ## train\n",
    "    total_epoch = 50\n",
    "    prev_loss = 10000\n",
    "    if phase == 'train':\n",
    "        for epoch in range(total_epoch):\n",
    "            if (epoch + 1)%10 ==0:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = param_group['lr'] * 0.1\n",
    "            for i, (imgs, atts, labels) in enumerate(train_loader, 0):\n",
    "\n",
    "                nb = labels.size(0)\n",
    "                net.zero_grad()\n",
    "                input.data.resize_(imgs.size()).copy_(imgs)\n",
    "                label.data.resize_(nb).copy_(labels)\n",
    "                input_att.data.resize_(atts.view(-1, 192).size()).copy_(atts.view(-1, 192))\n",
    "                output = net(input, input_att, nb)\n",
    "#                 print output.data\n",
    "#                 print label.data\n",
    "#                 ddd\n",
    "                loss = criterion(output, label)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                print 'Epoch: %d, iter:%d, Train loss is %f'%(epoch, i, loss.data[0])\n",
    "            # val\n",
    "            for i, (imgs, atts, labels) in enumerate(val_loader, 0):\n",
    "                nb = labels.size(0)\n",
    "                input.data.resize_(imgs.size()).copy_(imgs)\n",
    "                label.data.resize_(nb).copy_(labels)\n",
    "                input_att.data.resize_(atts.view(-1, 192).size()).copy_(atts.view(-1, 192))\n",
    "                output = net(input, input_att, nb)\n",
    "                loss = criterion(output, label)\n",
    "                print '---------------------------------------------'\n",
    "                print 'Epoch: %d, Val loss is %f, Loss decreases %f'%( epoch, loss.data[0], prev_loss - loss.data[0]) \n",
    "                print '---------------------------------------------'\n",
    "                prev_loss = loss.data[0]\n",
    "                \n",
    "            \n",
    "            \n",
    "            if epoch % 20 == 0 or epoch == total_epoch - 1:\n",
    "                torch.save(net.state_dict(), 'models/epoch_%d.pth'%(epoch))\n",
    "    else:\n",
    "        submission = leaf_save(trainset.classes)\n",
    "        imgs_test = []\n",
    "        imgs_class = []\n",
    "        results = []\n",
    "        imgs_name = testset.imgs\n",
    "        for i, (imgs, atts, _) in enumerate(test_loader, 0):\n",
    "            result_i = []\n",
    "            input.data.resize_(imgs.size()).copy_(imgs)\n",
    "            \n",
    "            origin_im = arr2unit8(input.data[0,:,:,:].cpu().numpy()[0,:,:])\n",
    "            origin_im = Image.fromarray(origin_im)\n",
    "            \n",
    "            input_att.data.resize_(atts.view(-1, 192).size()).copy_(atts.view(-1, 192))\n",
    "            output = net(input, input_att, 1)\n",
    "            output = functional.softmax(output).data.cpu().numpy()\n",
    "            max_idx = np.where(output.reshape(-1)== max(output.reshape(-1)))[0][0]\n",
    "            pred_class = trainset.classes[max_idx]\n",
    "            \n",
    "            img_name = imgs_name[i][0].split('/')[-1]\n",
    "            idx = str(int(img_name[0:img_name.find('.')]))\n",
    "            \n",
    "            ### write to csv\n",
    "            result_i.append(idx)\n",
    "            for op in output.reshape(99,):\n",
    "                result_i.append('%.6f'%op)\n",
    "            results.append(tuple(result_i))\n",
    "            ###visualization\n",
    "            imgs_test.append(origin_im)\n",
    "            imgs_class.append(pred_class)\n",
    "            \n",
    "        submission.write_data(results)\n",
    "        submission.close()\n",
    "        print 'finised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAAAAADH8yjkAAABC0lEQVR4nO2YwQ7CMAxDW/7/n8sJ\niWlrZzupsEZygUkjb89pOKy1qqpzjcHc/eL7c7fTALI/DWD7swC6vzCDrYBx+MgH8AHZRfQpQoUB\nKAlZRSQJqAY4zCiisbjKAGgTCESEAlGAKoAC5P6BUwQyMYAu4LQHp8K0IEAgIY+IIgIhAwgMAEIC\nHjP4HQAJz9sgBxA7RA4GqwLszA0KUIACPAJw/2fkblCA1lrruwHB+gvAagj3A3Iw2A8IHVQLg3kB\nbhAgkpF5RGmASUZIdCYG+wGXYUCHy8Xg6mmx7dANwO2DAeo24wZ9eZkAEB2YGfTJ9zTAV1fchvUe\n0q84BPd2xGaTC+BUwVdsVQ+sN+ZLIpoSiCMGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=96x96 at 0x7FF5D7AA9E50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
