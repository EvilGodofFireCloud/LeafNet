{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import model\n",
    "from model import weights_init\n",
    "from myfolder import ImageFolder\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import csv\n",
    "data_path = './dataset/leaves'\n",
    "\n",
    "#convert array to unit8 (ot display the image)\n",
    "def arr2unit8(arr):\n",
    "    #arr m*n\n",
    "#     img_numpy = input.data[0,:,:,:].cpu().numpy()[0,:,:] variable\n",
    "    res = np.zeros((arr.shape[0],arr.shape[1]),dtype=np.uint8)\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            if arr[i][j] > 0.5:\n",
    "                res[i][j] = 255\n",
    "    return res\n",
    "        \n",
    "#save results\n",
    "class leaf_save:\n",
    "    def __init__(self, classes, filename='sample_submission.csv'):\n",
    "        first_row = ['id']\n",
    "        first_row.extend(classes)\n",
    "        self.csvfile = file(filename, 'wb')\n",
    "        self.csv_writer = csv.writer(self.csvfile)\n",
    "        self.csv_writer.writerow(first_row)\n",
    "    \n",
    "    def write_data(self, result):\n",
    "        self.csv_writer.writerows(result)\n",
    "        \n",
    "    def close(self):\n",
    "        self.csvfile.close()\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #train or test\n",
    "    phase = 'test'\n",
    "    #batch size\n",
    "    nb = 512\n",
    "    is_cuda = True\n",
    "    random.seed(random.randint(1,10000))\n",
    "    torch.manual_seed(random.randint(1,10000))\n",
    "    pretrain_model = 'models/epoch_99.pth'\n",
    "#     pretrain_model = ''\n",
    "    #use cudnn\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    #Normalized to (0,1)\n",
    "    trainset = ImageFolder(root=data_path+'/train', \\\n",
    "            transform=transforms.Compose([\\\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0., 0., 0.),(1., 1., 1.))\n",
    "            ]))\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size = nb,\\\n",
    "            shuffle=True, num_workers = 2)\n",
    "    \n",
    "    testset = ImageFolder(root=data_path+'/test', \\\n",
    "            transform=transforms.Compose([\\\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0., 0., 0.),(1., 1., 1.))\n",
    "            ]))\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size = 1,\\\n",
    "            shuffle=False, num_workers = 2)\n",
    "\n",
    "    # network\n",
    "    net = model.leafnet(1)\n",
    "    net.apply(weights_init)\n",
    "    if pretrain_model != '':\n",
    "        print 'loading pretrained model'\n",
    "        net.load_state_dict(torch.load(pretrain_model))\n",
    "    \n",
    "    \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    input = torch.FloatTensor(nb, 1, 96, 96)\n",
    "    label = torch.LongTensor(nb)\n",
    "    input_att = torch.FloatTensor(nb, 192)\n",
    "    if is_cuda: \n",
    "        net.cuda()\n",
    "        criterion.cuda()\n",
    "        input = input.cuda()\n",
    "        label = label.cuda()\n",
    "        input_att = input_att.cuda()\n",
    "\n",
    "    input = Variable(input)\n",
    "    label = Variable(label)\n",
    "    input_att = Variable(input_att)\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.99)\n",
    "#     optimizer = optim.RMSprop(net.parameters(), lr = 0.01, momentum=0.9)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.005, betas = (.5, 0.99))\n",
    "    \n",
    "    ## train\n",
    "    if phase == 'train':\n",
    "        for epoch in range(100):\n",
    "            for i, (imgs, atts, labels) in enumerate(train_loader, 0):\n",
    "\n",
    "                nb = labels.size(0)\n",
    "                net.zero_grad()\n",
    "                input.data.resize_(imgs.size()).copy_(imgs)\n",
    "                label.data.resize_(nb).copy_(labels)\n",
    "                input_att.data.resize_(atts.view(-1, 192).size()).copy_(atts.view(-1, 192))\n",
    "                output = net(input, input_att, nb)\n",
    "                loss = criterion(output, label)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                print 'Epoch: %d, ite:%d, loss is %f'%(epoch, i, loss.data[0])\n",
    "            if epoch % 99 == 0:\n",
    "                torch.save(net.state_dict(), 'models/epoch_%d.pth'%(epoch))\n",
    "    else:\n",
    "        submission = leaf_save(trainset.classes)\n",
    "        imgs_test = []\n",
    "        imgs_class = []\n",
    "        results = []\n",
    "        imgs_name = testset.imgs\n",
    "        for i, (imgs, atts, _) in enumerate(test_loader, 0):\n",
    "            result_i = []\n",
    "            input.data.resize_(imgs.size()).copy_(imgs)\n",
    "            \n",
    "            origin_im = arr2unit8(input.data[0,:,:,:].cpu().numpy()[0,:,:])\n",
    "            origin_im = Image.fromarray(origin_im)\n",
    "            \n",
    "            input_att.data.resize_(atts.view(-1, 192).size()).copy_(atts.view(-1, 192))\n",
    "            output = net(input, input_att, 1).data.cpu().numpy()\n",
    "            max_idx = np.where(output.reshape(99,1)== max(output.reshape(99,1)))[0][0]\n",
    "            pred_class = trainset.classes[max_idx]\n",
    "            \n",
    "            img_name = imgs_name[i][0].split('/')[-1]\n",
    "            idx = str(int(img_name[0:img_name.find('.')]))\n",
    "            \n",
    "            ### write to csv\n",
    "            result_i.append(idx)\n",
    "            for op in output.reshape(99,):\n",
    "                result_i.append('%.6f'%op)\n",
    "            results.append(tuple(result_i))\n",
    "            ###visualization\n",
    "            imgs_test.append(origin_im)\n",
    "            imgs_class.append(pred_class)\n",
    "            \n",
    "        submission.write_data(results)\n",
    "        submission.close()\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAAAAADH8yjkAAABFElEQVR4nO2XQRaDIAxEE+9/Z7ux\nfQgJSWBYdf5KQeYLKKIIIYQQQgj5Q+6FNrqWnGuWuXJ60xnN9JrMkEQSvz4/4FOHV1mbz4nCrqo/\nLq7Cqlh5Gl3DWL4U7xuG4tV8T9EVbsQ7hguYbzbXoL7I2IemBJBvKC4RuW9c/hCjuOhXZn+CdbSG\ny71qg/Z2jwieWT0oaDrxCPKfwKrhVA9+Bu3Ooag0PcAP0pB75n0DL3Z9/HuSkaOkw4GI4Pqg5iHM\nYC12QINOT7cNQx5u22Kn4TZeXpi1Fq0+rpl90Rfcv4x7t1WFF+Qu18VxKu2uv0B+QbZ/oaKMYCQS\niiAhHuq5I2yfmsto17wtaCynvqyEEEIIIYR8ALDQLDEYbaNuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=96x96 at 0x7F2ABBB81410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Magnolia_Salicifolia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_class[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
